{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210</td>\n",
       "      <td>280</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>280</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>940</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>372</td>\n",
       "      <td>180</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "      <td>1230</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>120</td>\n",
       "      <td>640</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>184</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>310</td>\n",
       "      <td>630</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>760</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>203</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>320</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0                640            640             0   \n",
       "1             210                280            500             0   \n",
       "2              60                  0            710             0   \n",
       "3               0                  0              0             0   \n",
       "4               0                  0              0             0   \n",
       "5               0                  0              0             0   \n",
       "6               0                  0              0             0   \n",
       "7               0                  0              0             0   \n",
       "8             150                  0            460             0   \n",
       "9              60                120            770             0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0            320               0                 0                   0   \n",
       "1            140             280               210                  70   \n",
       "2           1230             190               190                 120   \n",
       "3            630               0               310                 630   \n",
       "4            630               0               310                 630   \n",
       "5           1850               0                 0                1850   \n",
       "6           1920               0                 0                   0   \n",
       "7           1880               0                 0                1880   \n",
       "8            610               0               300                   0   \n",
       "9            190             320               380                   0   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  word_freq_edu  word_freq_table  \\\n",
       "0                0               0  ...              0                0   \n",
       "1                0             940  ...              0                0   \n",
       "2              640             250  ...             60                0   \n",
       "3              310             630  ...              0                0   \n",
       "4              310             630  ...              0                0   \n",
       "5                0               0  ...              0                0   \n",
       "6                0             640  ...              0                0   \n",
       "7                0               0  ...              0                0   \n",
       "8              920             760  ...              0                0   \n",
       "9               60               0  ...              0                0   \n",
       "\n",
       "   word_freq_conference  char_freq_;  char_freq_(  char_freq_[  char_freq_!  \\\n",
       "0                     0            0            0            0          778   \n",
       "1                     0            0          132            0          372   \n",
       "2                     0           10          143            0          276   \n",
       "3                     0            0          137            0          137   \n",
       "4                     0            0          135            0          135   \n",
       "5                     0            0          223            0            0   \n",
       "6                     0            0           54            0          164   \n",
       "7                     0            0          206            0            0   \n",
       "8                     0            0          271            0          181   \n",
       "9                     0           40           30            0          244   \n",
       "\n",
       "   char_freq_$  char_freq_#  spam  \n",
       "0            0            0     1  \n",
       "1          180           48     1  \n",
       "2          184           10     1  \n",
       "3            0            0     1  \n",
       "4            0            0     1  \n",
       "5            0            0     1  \n",
       "6           54            0     1  \n",
       "7            0            0     1  \n",
       "8          203           22     1  \n",
       "9           81            0     1  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"dataset/spambase.csv\")\n",
    "# Show the first 10 rows of the dataset\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. More frequent words in SPAM and NO SPAM emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the most common words in spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "you         4105599\n",
       "your        2502597\n",
       "will         997100\n",
       "free         939790\n",
       "our          931799\n",
       "all          732080\n",
       "mail         635470\n",
       "email        578759\n",
       "business     521250\n",
       "remove       499309\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agrupate by spam and sum the values\n",
    "column_sum = dataset.groupby('spam', as_index=False).sum()\n",
    "# Select only the columns that represent the frequency of words\n",
    "word_columns = [col for col in dataset.columns if col.startswith('word_freq_')]\n",
    "# Extract the frequencies of words in spam emails\n",
    "spam_word_frequencies = column_sum.loc[1, word_columns]\n",
    "# Order the frequencies from highest to lowest\n",
    "most_used_words_in_spam = spam_word_frequencies.sort_values(ascending=False)\n",
    "# Get the top 10 most used words in spam emails\n",
    "top_10_spam_words = most_used_words_in_spam.head(10)\n",
    "# Remove 'word_freq_' from the column names\n",
    "top_10_spam_words.index = top_10_spam_words.index.str.replace('word_freq_', '')\n",
    "top_10_spam_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the most common words in non-spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "you        3541702\n",
       "george     3527559\n",
       "hp         2496576\n",
       "will       1495268\n",
       "your       1223098\n",
       "hpl        1204398\n",
       "re         1159138\n",
       "edu         800669\n",
       "address     681569\n",
       "meeting     604460\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the frequencies of words in non-spam emails\n",
    "non_spam_word_frequencies = column_sum.loc[0, word_columns]\n",
    "# Order the frequencies from highest to lowest\n",
    "most_used_words_in_non_spam = non_spam_word_frequencies.sort_values(ascending=False)\n",
    "# Get the top 10 most used words in non-spam emails\n",
    "top_10_non_spam_words = most_used_words_in_non_spam.head(10)\n",
    "# Remove 'word_freq_' from the column names\n",
    "top_10_non_spam_words.index = top_10_non_spam_words.index.str.replace('word_freq_', '')\n",
    "top_10_non_spam_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset split into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 3220 samples.\n",
      "Testing set has 1381 samples.\n"
     ]
    }
   ],
   "source": [
    "# Create the X characteristics matrix by dropping the 'spam' column\n",
    "X = dataset.drop('spam', axis=1)\n",
    "# Create the y target vector by selecting only the 'spam' column\n",
    "y = dataset['spam']\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "# Print the number of samples in each set\n",
    "print(f\"Training set has {X_train.shape[0]} samples.\")\n",
    "print(f\"Testing set has {X_test.shape[0]} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp3_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
